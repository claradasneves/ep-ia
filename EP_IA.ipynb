{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGUvj5itk-3m"
      },
      "source": [
        "# Trabalho de IA: MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuOcZ8Nto_bY"
      },
      "source": [
        "- Fazer leitura dos dados testes\n",
        "- Fazer o loop das épocas\n",
        "- Conferir o backpropagation\n",
        "- Testar com conj binários\n",
        "\n",
        "Depois:\n",
        "Otimização e análise\n",
        "- Parada antecipada\n",
        "- Rever o doc de especificação do trabalho para montar os gráficos\n",
        "- Começar a guardar os pesos (e perguntar pra prof o porquê)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN8ONKTblF9z"
      },
      "source": [
        "##Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uRTRIhbRmLbE"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_0sIq_i-l53g"
      },
      "outputs": [],
      "source": [
        "alfabeto = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "\n",
        "def letra_para_vetor(letra):\n",
        "    \"\"\"\n",
        "    Transforma um caractere num vetor de 26 posições, no qual a posição da letra correspondente é 1 e o restante é -1.\n",
        "    :param letra: Letra a ser transformada num vetor\n",
        "    :return: Vetor binário de 26 posições\n",
        "    \"\"\"\n",
        "    vetor = [-1] * 26\n",
        "    pos_letra = alfabeto.index(letra)\n",
        "    vetor[pos_letra] = 1\n",
        "\n",
        "    return vetor\n",
        "\n",
        "def vetor_para_letra(vetor):\n",
        "    \"\"\"\n",
        "    Encontra a letra do alfabeto correspondente a um vetor de 26 posições.\n",
        "    :param vetor: Vetor de 26 posições que representa uma letra do alfabeto.\n",
        "    :return: Letra correspondente.\n",
        "    \"\"\"\n",
        "    # Encontra a posição do maior valor no vetor\n",
        "    maior_pos = np.argmax(vetor)\n",
        "\n",
        "    # Encontra a letra correspondente no alfabeto\n",
        "    letra = alfabeto[maior_pos]\n",
        "\n",
        "    return letra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ler_arq_imagens(nome_arq):\n",
        "    \"\"\"\n",
        "    Lê o arquivo de imagens e retorna um array numpy.\n",
        "\n",
        "    Args:\n",
        "        nome_arq (str): Caminho para o arquivo de imagens.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array numpy contendo as imagens.\n",
        "    \"\"\"\n",
        "    with open(nome_arq, 'r') as file:\n",
        "        data = file.read().strip().split('\\n')\n",
        "    data = [list(map(int, filter(lambda x: x.strip(), line.split(',')))) for line in data if line.strip()]\n",
        "    return np.array(data)\n",
        "\n",
        "def ler_arq_classes(nome_arq):\n",
        "    \"\"\"\n",
        "    Lê o arquivo de classes e retorna um array numpy.\n",
        "\n",
        "    Args:\n",
        "        nome_arq (str): Caminho para o arquivo de classes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array numpy contendo as classes.\n",
        "    \"\"\"\n",
        "    with open(nome_arq, 'r') as file:\n",
        "        data = []\n",
        "        for line in file:\n",
        "            vetor_letra = letra_para_vetor(line[0])\n",
        "            data.append(vetor_letra)\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dividir_dados(entrada, classes, div_proportion=0.2):\n",
        "    \"\"\"\n",
        "        Divide dois vetores de dados em uma determinada proporção (padrão: 80/20).\n",
        "\n",
        "        Args:\n",
        "            entrada (np.array): Vetor dos dados a serem divididos.\n",
        "            classes (np.array): Classificação dos dados a serem dividos.\n",
        "            div_proportion (float): Proporção da divisão dos dados (padrão: 20%)\n",
        "\n",
        "        Returns:\n",
        "            dados_primeira_parte (np.array): Vetor de dados da primeira parte da divisão.\n",
        "            classes_primeira_parte (np.array): Vetor de classificação dos dados da primeira parte da divisão.\n",
        "            dados_segunda_parte (np.array): Vetor de dados da segunda parte da divisão.\n",
        "            classes_segunda_parte (np.array): Vetor de classificação dos dados da segunda parte da divisão.\n",
        "        \"\"\"\n",
        "    # Embaralha os índices para os dados serem divididos de forma aleatória\n",
        "    print(entrada.shape[0])\n",
        "    print(classes.shape[0])\n",
        "    indices = np.arange(entrada.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Obtém o índice da separação dos dados\n",
        "    indice_split = int(len(indices) * (1 - div_proportion))\n",
        "\n",
        "    # Divide o vetor de indíce em duas partes\n",
        "    primeira_parte = indices[:indice_split]\n",
        "    segunda_parte = indices[indice_split:]\n",
        "    \n",
        "    # Define os vetores de cada parte\n",
        "    dados_primeira_parte = entrada[primeira_parte]\n",
        "    classes_primeira_parte = classes[primeira_parte]\n",
        "    dados_segunda_parte = entrada[segunda_parte]\n",
        "    classes_segunda_parte = classes[segunda_parte]\n",
        "\n",
        "    return dados_primeira_parte, classes_primeira_parte, dados_segunda_parte, classes_segunda_parte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-hoEUDxPfc4"
      },
      "source": [
        "Funcao pra reconstruir imagens a partir do array de array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nD_uUiPPEYlC",
        "outputId": "a9db9514-13b0-4b09-d43e-b36ca64d539c"
      },
      "outputs": [],
      "source": [
        "def reconstruct_image(row_index, image_array):\n",
        "    \"\"\"\n",
        "    Reconstrói e plota uma imagem a partir do array numpy.\n",
        "\n",
        "    Args:\n",
        "        row_index (int): Índice da linha da imagem a ser reconstruída.\n",
        "        image_array (np.ndarray): Array numpy contendo as imagens.\n",
        "    \"\"\"\n",
        "    image_array = image_array[row_index]\n",
        "    image_reshaped = np.reshape(image_array, (10, 12))\n",
        "\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    plt.imshow(image_reshaped, cmap='gray')\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEMCAYAAAAPqefdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsqUlEQVR4nO3de1QUV4I/8G8D0ojSjYRHg0FBTUTiMyAdTGbiBA6gTEZ2XaP5kVEZAxOFGMXEx5woKjHE6LqujhOSrPg4o1EzG81zUIJBTyIiQZ1EQxh1jBClwUfoFoyAdP3+yKHWErroAhoK+X7OqRP79q3qW930N7dv3arSCIIggIiIegSn7m4AERHZj6FNRNSDMLSJiHoQhjYRUQ/C0CYi6kEY2kREPQhDm4ioB2FoExH1IAxtIqIehKFNRNSDMLSJqFc4evQonn76aQQEBECj0eDAgQNtrlNQUIBHH30UWq0Ww4YNw/bt21vU2bJlC4KCguDm5gaj0YgTJ050fuPvwtAmol6hrq4OY8aMwZYtW+yqf/HiRcTHx+M3v/kNTp8+jQULFuD555/HwYMHxTp79+5Feno6MjIycPLkSYwZMwaxsbGorq521G5AwwtGEVFvo9FosH//fiQkJNiss2TJEnz66ac4c+aMWDZjxgzU1NQgNzcXAGA0GjF+/Hj8+c9/BgBYrVYEBgbixRdfxNKlSx3SdheHbJWIqB1u376NhoYGu+sLggCNRiMp02q10Gq1HW5LYWEhoqOjJWWxsbFYsGABAKChoQElJSVYtmyZ+LyTkxOio6NRWFjY4de3haFNRKpw+/ZtBAcHw2Qy2b1O//79UVtbKynLyMjAypUrO9wek8kEPz8/SZmfnx8sFgt+/vln/PTTT2hqamq1zvfff9/h17eFoU1EqtDQ0ACTyYTy8nLodLo261ssFgwaNAgVFRWS+p3Ry1YzhjYRqYqHhwc8PDzarNd8OE6n09kV8koZDAZUVVVJyqqqqqDT6dC3b184OzvD2dm51ToGg6HT29OMs0eISFUEQbB7caTIyEjk5+dLyvLy8hAZGQkAcHV1RVhYmKSO1WpFfn6+WMcRGNpEpCqOCu3a2lqcPn0ap0+fBvDLlL7Tp0+jvLwcALBs2TLMnDlTrP/CCy/gX//6FxYvXozvv/8ef/nLX7Bv3z4sXLhQrJOeno53330XO3bsQGlpKebOnYu6ujokJSV1/I2wRSAiUgGz2SwAEK5duyY0NDS0uVy7dk0AIJjNZru2/8UXXwgAWiyzZs0SBEEQZs2aJTz55JMt1hk7dqzg6uoqDBkyRNi2bVuL7W7evFkYNGiQ4OrqKkRERAjHjx/v4Dshj/O0iUgVLBYL9Ho9rl69aveBSB8fH5jNZoeMaasVD0QSkaoIdg599Nb+JkObiFSFoS2PoU1EqmK1WmG1Wu2q1xsxtIlIVdjTlsfQJiJVYWjL6/LQtlqtuHLlCjw8PFpc6IWIejZBEHDz5k0EBATAyal9p4EwtOV1eWhfuXIFgYGBXf2yRNSFKioq8OCDD7ZrXYa2vC4P7eZrCtx7kRe10ev13d0Eug+YzebubkKXslgsCAwMtOvaIbYwtOV1eWg3D4k46iIvRGrSW//GOzL0ydCWxwORRKQqDG15DG0iUhWGtrx2Hd7t6rsPE1HvIQiCeIKN3MLQtlN33H2YiHqP5p62PUtvpDi0N2zYgOTkZCQlJSE0NBTZ2dlwd3dHTk6OI9pHRL0MQ1ueotBuvvvw3Xco7oq7DxNR78HQlqfoQOS1a9cU3324vr4e9fX14mOLxdKOZhJRb8EDkfIcfruxrKws6PV6ceHZkEQkhz1teYpC29vbW/Hdh5ctWwaz2SwuFRUV7W8tEd33GNryFIV2e+4+rNVqxbMfeRYkEbXFkaGtZLryxIkTodFoWizx8fFindmzZ7d4Pi4url37bS/FJ9ekp6dj1qxZCA8PR0REBDZu3Oj4uw8TUa/hqDHt5unK2dnZMBqN2LhxI2JjY1FWVgZfX98W9T/44AM0NDSIj69fv44xY8Zg2rRpknpxcXHYtm2b+Fir1Spql1KKQ3v69Om4evUqVqxYAZPJhLFjxyI3N7fFwUkiovZwVGjfPV0ZALKzs/Hpp58iJycHS5cubVHfy8tL8njPnj1wd3dvEdpardbm8LAjtOtAZFpaGi5duoT6+noUFRXBaDR2druIqJey52zIu29JZrFYJMvds9WadcZ05a1bt2LGjBno16+fpLygoAC+vr4YPnw45s6di+vXr3dg79vm8NkjRERKKB3TDgwMlMxQy8rKarFNuenKJpOpzTadOHECZ86cwfPPPy8pj4uLw86dO5Gfn4+1a9fiyJEjmDRpEpqamjrwDsjjBaOISFWUDo/ce21+R4wpb926FaNGjUJERISkfMaMGeK/R40ahdGjR2Po0KEoKChAVFRUp7cDYE+biFRGaU/73tlprYV2e6YrN6urq8OePXswZ86cNts+ZMgQeHt74/z58wr2WBmGNhGpiiOm/LVnunKz999/H/X19XjuuefafJ0ff/wR169fh7+/v91tU4rDIz1cbz3BgO5fjpo90tZ05ZkzZ2LgwIEtxsS3bt2KhIQEPPDAA5Ly2tparFq1ClOnToXBYMCFCxewePFiDBs2DLGxsYrapgRDm4hUxxGdkbamK5eXl7e4g3xZWRm+/PJLHDp0qMX2nJ2d8c0332DHjh2oqalBQEAAYmJikJmZ6dC52hqhi7tqFosFer0eZrNZ1WdHduQed12JPW1Sk458v5vXLSkpQf/+/dusX1tbi7CwMNVnSWdjT5uIVIVX+ZPH0CYiVbn7xJm26vVGDG0iUhX2tOUxtIlIVRja8hjaRKQqDG15DG0iUhWGtjyGNhGpCkNbHkObiFSFoS2PoU1EqsLQlsfQJiJVYWjLY2gTkarw5Bp5DG0iUhX2tOUxtIlIVRja8hjaRKQqDG15DG0iUp3eGsj2YGgTkaqwpy2PoU1EqsLQlsfQJiJVYWjL493YiUhVHHE39mZbtmxBUFAQ3NzcYDQaceLECZt1t2/fDo1GI1nc3NxatHXFihXw9/dH3759ER0djXPnzilulxIMbSJSleaTa+xZlNi7dy/S09ORkZGBkydPYsyYMYiNjUV1dbXNdXQ6HSorK8Xl0qVLkufffPNNbNq0CdnZ2SgqKkK/fv0QGxuL27dvt2vf7cHQJiJVcVRPe8OGDUhOTkZSUhJCQ0ORnZ0Nd3d35OTk2FxHo9HAYDCIS/Od25vbuXHjRrz66quYMmUKRo8ejZ07d+LKlSs4cOBAe3e/TQxtIlIVpaFtsVgkS319fYttNjQ0oKSkBNHR0WKZk5MToqOjUVhYaLMttbW1GDx4MAIDAzFlyhScPXtWfO7ixYswmUySber1ehiNRtltdhRDm4hURWloBwYGQq/Xi0tWVlaLbV67dg1NTU2SnjIA+Pn5wWQytdqO4cOHIycnBx9++CH++te/wmq1YsKECfjxxx8BQFxPyTY7A2ePEJGqKJ09UlFRAZ1OJ5ZrtdpOaUdkZCQiIyPFxxMmTMCIESPw9ttvIzMzs1Neoz0U9bSzsrIwfvx4eHh4wNfXFwkJCSgrK3NU24ioF1La09bpdJKltdD29vaGs7MzqqqqJOVVVVUwGAx2tatPnz4YN24czp8/DwDieh3ZZnsoCu0jR44gNTUVx48fR15eHhobGxETE4O6ujpHtY+IehlHHIh0dXVFWFgY8vPzxTKr1Yr8/HxJb1pOU1MTvv32W/j7+wMAgoODYTAYJNu0WCwoKiqye5vtoWh4JDc3V/J4+/bt8PX1RUlJCX796193asOIqHdy1Mk16enpmDVrFsLDwxEREYGNGzeirq4OSUlJAICZM2di4MCB4pj46tWr8dhjj2HYsGGoqanBunXrcOnSJTz//PMAfplZsmDBArz22mt46KGHEBwcjOXLlyMgIAAJCQnKdlqBDo1pm81mAICXl5fNOvX19ZKjuRaLpSMvSUT3OUeF9vTp03H16lWsWLECJpMJY8eORW5urnggsby8HE5O/zf48NNPPyE5ORkmkwkDBgxAWFgYjh07htDQULHO4sWLUVdXh5SUFNTU1OCJJ55Abm5ui5NwOpNGaOe5oFarFb/73e9QU1ODL7/80ma9lStXYtWqVS3KzWaz5OCB2mg0mu5ugl1666m8pE4WiwV6vb5d3+/mdT/44AP069evzfp1dXX493//d9VnSWdr95S/1NRUnDlzBnv27JGtt2zZMpjNZnGpqKho70sSUS/gqDMi7xftGh5JS0vDJ598gqNHj+LBBx+UravVajttCg4R9Q78BWmbotAWBAEvvvgi9u/fj4KCAgQHBzuqXUTUS/Eqf/IUhXZqaip2796NDz/8EB4eHuJZP3q9Hn379nVIA4mod2Foy1M0pv3WW2/BbDZj4sSJ8Pf3F5e9e/c6qn1E1Ms48tKs9wPFwyNERI7EnrY8XnuEiFSFoS2PoU1EqsLQlsfQJiJVYWjLY2gTkarYe+IMT64hIlIB9rTlMbSJSFUY2vIY2kSkKgxteQxtIlIVhrY8hjYRqQpDWx5Dm4hUhaEtj6FNRKrC0JbH0CYiVWFoy2v3nWuIiBxBEAS77lrTntDesmULgoKC4ObmBqPRiBMnTtis++677+JXv/oVBgwYgAEDBiA6OrpF/dmzZ0Oj0UiWuLg4xe1SgqFNRKriqEuz7t27F+np6cjIyMDJkycxZswYxMbGorq6utX6BQUFePbZZ/HFF1+gsLAQgYGBiImJweXLlyX14uLiUFlZKS7vvfdeu/fdHgxtIlIVR4X2hg0bkJycjKSkJISGhiI7Oxvu7u7Iyclptf6uXbswb948jB07FiEhIfif//kfWK1W5OfnS+pptVoYDAZxGTBgQLv33R4MbSJSFaWhbbFYJEt9fX2LbTY0NKCkpATR0dFimZOTE6Kjo1FYWGhXu27duoXGxkZ4eXlJygsKCuDr64vhw4dj7ty5uH79egf2vm0MbSJSFaWhHRgYCL1eLy5ZWVkttnnt2jU0NTXBz89PUu7n5yfeNrEtS5YsQUBAgCT44+LisHPnTuTn52Pt2rU4cuQIJk2ahKampg68A/I4e4SIVEXp7JGKigrodDqxXKvVdnqb3njjDezZswcFBQVwc3MTy2fMmCH+e9SoURg9ejSGDh2KgoICREVFdXo7APa0iUhllPa0dTqdZGkttL29veHs7IyqqipJeVVVFQwGg2x71q9fjzfeeAOHDh3C6NGjZesOGTIE3t7eOH/+vMK9th9Dm4hUxREHIl1dXREWFiY5iNh8UDEyMtLmem+++SYyMzORm5uL8PDwNl/nxx9/xPXr1+Hv729325RiaBORqjhq9kh6ejreffdd7NixA6WlpZg7dy7q6uqQlJQEAJg5cyaWLVsm1l+7di2WL1+OnJwcBAUFwWQywWQyoba2FgBQW1uLV155BcePH8cPP/yA/Px8TJkyBcOGDUNsbGznvSH34Jg2EamKo+5cM336dFy9ehUrVqyAyWTC2LFjkZubKx6cLC8vh5PT//Vj33rrLTQ0NOA//uM/JNvJyMjAypUr4ezsjG+++QY7duxATU0NAgICEBMTg8zMTIeMqzdjaBORqjjyNPa0tDSkpaW1+lxBQYHk8Q8//CC7rb59++LgwYOK29BRDG0iUhVee0QeQ7uH02g03d2E+0ZvDQG1YWjLY2gTkaowtOUxtIlIVRja8hjaRKQqDG15DG0iUhWGtjyGNhGpTm8NZHt06IzIN954AxqNBgsWLOik5hBRb+eoMyLvF+3uaRcXF+Ptt99u8wIqRERKOOqMyPtFu3ratbW1SExMxLvvvuvwuzQQUe/Cnra8doV2amoq4uPjJRcDJyLqDAxteYqHR/bs2YOTJ0+iuLjYrvr19fWS2/9YLBalL0lEvQhnj8hT1NOuqKjASy+9hF27dknu3iAnKytLciugwMDAdjWUiHoH9rTlKQrtkpISVFdX49FHH4WLiwtcXFxw5MgRbNq0CS4uLq3eF23ZsmUwm83iUlFR0WmNJ6L7D0NbnqLhkaioKHz77beSsqSkJISEhGDJkiVwdnZusY5Wq3XotWWJ6P7C4RF5ikLbw8MDI0eOlJT169cPDzzwQItyIqL2YGjL4xmRRKQqDG15HQ7te+/2QETUETy5Rh5v7EtEquLIA5FbtmxBUFAQ3NzcYDQaceLECdn677//PkJCQuDm5oZRo0bhs88+a9HWFStWwN/fH3379kV0dDTOnTunuF1KMLSJSFUcFdp79+5Feno6MjIycPLkSYwZMwaxsbGorq5utf6xY8fw7LPPYs6cOTh16hQSEhKQkJCAM2fOiHXefPNNbNq0CdnZ2SgqKkK/fv0QGxuL27dvd+g9kMPQJiJVcVRob9iwAcnJyUhKSkJoaCiys7Ph7u6OnJycVuv/93//N+Li4vDKK69gxIgRyMzMxKOPPoo///nPYjs3btyIV199FVOmTMHo0aOxc+dOXLlyBQcOHOjo22ATQ7uHU/IHzoVzfnsCpZ+ZxWKRLHefgd2soaEBJSUlkktvODk5ITo6GoWFha22o7CwsMWlOmJjY8X6Fy9ehMlkktTR6/UwGo02t9kZGNpEpDpK/icbGBgoOes6KyurxfauXbuGpqYm+Pn5Scr9/PxgMplabYPJZJKt3/xfJdvsDJzyR0SqYu8vn+Y6FRUV0Ol0Yvn9fjIfe9pEpCpKh0d0Op1kaS20vb294ezsjKqqKkl5VVUVDAZDq+0wGAyy9Zv/q2SbnYGhTUSq4ojjEK6urggLC0N+fr5YZrVakZ+fj8jIyFbXiYyMlNQHgLy8PLF+cHAwDAaDpI7FYkFRUZHNbXYGDo8Qkao46uSa9PR0zJo1C+Hh4YiIiMDGjRtRV1eHpKQkAMDMmTMxcOBAcUz8pZdewpNPPon//M//RHx8PPbs2YOvv/4a77zzDgCIt1p87bXX8NBDDyE4OBjLly9HQEAAEhISlO20AgxtIlIVpWPa9po+fTquXr2KFStWwGQyYezYscjNzRUPJJaXl8PJ6f8GHyZMmIDdu3fj1VdfxZ/+9Cc89NBDOHDggOQ6S4sXL0ZdXR1SUlJQU1ODJ554Arm5uXZfuro9NEIXz3WyWCzQ6/Uwm82Sgwdqo9FoursJduFUNVKTjny/m9dduHChXQcT6+vr8V//9V+qz5LOxp42EamKo3ra9wuGNhGpCkNbHkObiFSFoS2PoU1EqsLQlsfQJiJVYWjLY2gTkaowtOUxtIlIVXjnGnkMbSJSFfa05TG0iUhVGNryGNpEpDq9NZDtwdAmIlVhT1seQ5uIVIWhLY+hTUSqwtCWx9AmIlVhaMtjaBORqjC05TG0iUhVGNryGNpEpCo8I1Ieb+xLRKriiBv7KnXjxg0kJiZCp9PB09MTc+bMQW1trWz9F198EcOHD0ffvn0xaNAgzJ8/H2azWVJPo9G0WPbs2aOobexpE5GqqGF4JDExEZWVlcjLy0NjYyOSkpKQkpKC3bt3t1r/ypUruHLlCtavX4/Q0FBcunQJL7zwAq5cuYK//e1vkrrbtm1DXFyc+NjT01NR2xjaRKQq3R3apaWlyM3NRXFxMcLDwwEAmzdvxuTJk7F+/XoEBAS0WGfkyJH43//9X/Hx0KFDsWbNGjz33HO4c+cOXFz+L2o9PT1hMBja3T7FwyOXL1/Gc889hwceeAB9+/bFqFGj8PXXX7e7AUREd+vu4ZHCwkJ4enqKgQ0A0dHRcHJyQlFRkd3bab7h8N2BDQCpqanw9vZGREQEcnJyFO+Hop72Tz/9hMcffxy/+c1v8Pe//x0+Pj44d+4cBgwYoOhFiYhsUdrTtlgsknKtVmvX3dxtMZlM8PX1lZS5uLjAy8sLJpPJrm1cu3YNmZmZSElJkZSvXr0aTz31FNzd3XHo0CHMmzcPtbW1mD9/vt3tUxTaa9euRWBgILZt2yaWBQcHK9kEEZEspaEdGBgoKc/IyMDKlStb1F+6dCnWrl0ru83S0lL7G2qDxWJBfHw8QkNDW7Rj+fLl4r/HjRuHuro6rFu3znGh/dFHHyE2NhbTpk3DkSNHMHDgQMybNw/Jyck216mvr0d9fb34+N7/KxIR3U1paFdUVECn04nltnrZixYtwuzZs2W3OWTIEBgMBlRXV0vK79y5gxs3brQ5Fn3z5k3ExcXBw8MD+/fvR58+fWTrG41GZGZmor6+3u5fB4pC+1//+hfeeustpKen409/+hOKi4sxf/58uLq6YtasWa2uk5WVhVWrVil5GSLqxZSGtk6nk4S2LT4+PvDx8WmzXmRkJGpqalBSUoKwsDAAwOHDh2G1WmE0Gm2uZ7FYEBsbC61Wi48++ghubm5tvtbp06cxYMAARcM5GkHBKLirqyvCw8Nx7NgxsWz+/PkoLi5GYWFhq+u01tMODAwUB+nVSqPRdHcT7NJbzwojdbJYLNDr9e36fjev+8wzz7TZQwWAxsZG7Nu3zyFZMmnSJFRVVSE7O1uc8hceHi5O+bt8+TKioqKwc+dOREREwGKxICYmBrdu3cL+/fvRr18/cVs+Pj5wdnbGxx9/jKqqKjz22GNwc3NDXl4eXn75Zbz88suKOraKetr+/v4IDQ2VlI0YMUIy1eVeHT0oQES9S3dP+QOAXbt2IS0tDVFRUXBycsLUqVOxadMm8fnGxkaUlZXh1q1bAICTJ0+KM0uGDRsm2dbFixcRFBSEPn36YMuWLVi4cCEEQcCwYcOwYcMG2eHl1igK7ccffxxlZWWSsn/+858YPHiwohclIrJFDaHt5eVl80QaAAgKCpK8/sSJE9tsT1xcnOSkmvZSNE974cKFOH78OF5//XWcP38eu3fvxjvvvIPU1NQON4SICOj+edpqpyi0x48fj/379+O9997DyJEjkZmZiY0bNyIxMdFR7SOiXoahLU/xaey//e1v8dvf/tYRbSEiUsXwiJrx2iNEpCoMbXkMbSJSFYa2PIY2EakKQ1seQ5uIVIV3rpHH0CYiVWFPWx5Dm4hUhaEtj6FNRKrC0JbH0CYiVWFoy2NoE5GqMLTlMbSJSFUY2vIY2kSkKgxteQxtIlIVhrY8hjYRqYogCHadOMPQJiJSAfa05TG0iUhVGNryFN0EgYjI0dRwE4QbN24gMTEROp0Onp6emDNnDmpra2XXmThxIjQajWR54YUXJHXKy8sRHx8Pd3d3+Pr64pVXXsGdO3cUtY09bSJSFTX0tBMTE1FZWYm8vDzxbuwpKSmy940EgOTkZKxevVp87O7uLv67qakJ8fHxMBgMOHbsGCorKzFz5kz06dMHr7/+ut1tY2gTkap0d2iXlpYiNzcXxcXFCA8PBwBs3rwZkydPxvr16xEQEGBzXXd3dxgMhlafO3ToEL777jt8/vnn8PPzw9ixY5GZmYklS5Zg5cqVcHV1tat9HB4hIlXp7uGRwsJCeHp6ioENANHR0XByckJRUZHsurt27YK3tzdGjhyJZcuW4datW5Ltjho1Cn5+fmJZbGwsLBYLzp49a3f72NMmIlVR2tO2WCyScq1WC61W2+7XN5lM8PX1lZS5uLjAy8sLJpPJ5nr/7//9PwwePBgBAQH45ptvsGTJEpSVleGDDz4Qt3t3YAMQH8tt914MbSJSFaWhHRgYKCnPyMjAypUrW9RfunQp1q5dK7vN0tJS+xt6j5SUFPHfo0aNgr+/P6KionDhwgUMHTq03du9F0ObiFRF6Z1rKioqoNPpxHJbvexFixZh9uzZstscMmQIDAYDqqurJeV37tzBjRs3bI5Xt8ZoNAIAzp8/j6FDh8JgMODEiROSOlVVVQCgaLsMbSJSFaU9bZ1OJwltW3x8fODj49NmvcjISNTU1KCkpARhYWEAgMOHD8NqtYpBbI/Tp08DAPz9/cXtrlmzBtXV1eLwS15eHnQ6HUJDQ+3eLg9EEpGqdPeByBEjRiAuLg7Jyck4ceIEvvrqK6SlpWHGjBnizJHLly8jJCRE7DlfuHABmZmZKCkpwQ8//ICPPvoIM2fOxK9//WuMHj0aABATE4PQ0FD8/ve/xz/+8Q8cPHgQr776KlJTUxWNwTO0iUhVuju0gV9mgYSEhCAqKgqTJ0/GE088gXfeeUd8vrGxEWVlZeLsEFdXV3z++eeIiYlBSEgIFi1ahKlTp+Ljjz8W13F2dsYnn3wCZ2dnREZG4rnnnsPMmTMl87rtoRG6+FxQi8UCvV4Ps9ls10+a7qLRaLq7CXbprafykjp15PvdvO748ePh4tL2yO2dO3dQXFys+izpbBzTJiJV6e6Ta9SOoU1EqsLQlsfQJiLV6a2BbA+GNhGpCnva8hTNHmlqasLy5csRHByMvn37YujQocjMzOy1bx4RdT41zB5RM0U97bVr1+Ktt97Cjh078Mgjj+Drr79GUlIS9Ho95s+f76g2ElEvYrVa7Zq9Zc9Zk/cjRaF97NgxTJkyBfHx8QCAoKAgvPfeey1OzSQiai8Oj8hTNDwyYcIE5Ofn45///CcA4B//+Ae+/PJLTJo0yeY69fX1sFgskoWIyBYOj8hT1NNeunQpLBYLQkJC4OzsjKamJqxZswaJiYk218nKysKqVas63FAi6h3Y05anqKe9b98+7Nq1C7t378bJkyexY8cOrF+/Hjt27LC5zrJly2A2m8WloqKiw40movsXe9ryFPW0X3nlFSxduhQzZswA8Ms1Yy9duoSsrCzMmjWr1XU6ekFyIupd2NOWpyi0b926BScnaefc2dm51x7FJaLOx9CWpyi0n376aaxZswaDBg3CI488glOnTmHDhg34wx/+4Kj2EVEvw9CWpyi0N2/ejOXLl2PevHmorq5GQEAA/vjHP2LFihWOah8R9TIMbXmKQtvDwwMbN27Exo0bHdQcIurteHKNPF57hIhUhT1teQxtIlIVhrY8hjYRqQpDWx7vEUlEqtPdJ9bcuHEDiYmJ0Ol08PT0xJw5c1BbW2uz/g8//ACNRtPq8v7774v1Wnt+z549itrGnjYRqYoaetqJiYmorKxEXl4eGhsbkZSUhJSUFOzevbvV+oGBgaisrJSUvfPOO1i3bl2LazNt27YNcXFx4mNPT09FbWNoE5GqdHdol5aWIjc3F8XFxQgPDwfwy3TnyZMnY/369QgICGixjrOzMwwGg6Rs//79eOaZZ9C/f39JuaenZ4u6SnB4hIhUpbuvPVJYWAhPT08xsAEgOjoaTk5OKCoqsmsbJSUlOH36NObMmdPiudTUVHh7eyMiIgI5OTmK94M9bSJSFaU97Xsv99zR6x2ZTCb4+vpKylxcXODl5QWTyWTXNrZu3YoRI0ZgwoQJkvLVq1fjqaeegru7Ow4dOoR58+ahtrZW0U1k2NMmIlWxWq12L8Av48l6vV5csrKyWt3u0qVLbR4sbF6+//77Drf/559/xu7du1vtZS9fvhyPP/44xo0bhyVLlmDx4sVYt26dou2zp01EqqK0p11RUQGdTieW2+plL1q0CLNnz5bd5pAhQ2AwGFBdXS0pv3PnDm7cuGHXWPTf/vY33Lp1CzNnzmyzrtFoRGZmJurr6+3+dcDQJiJVURraOp1OEtq2+Pj4wMfHp816kZGRqKmpQUlJCcLCwgAAhw8fhtVqhdFobHP9rVu34ne/+51dr3X69GkMGDBA0XAOQ5uIVKW7Z4+MGDECcXFxSE5ORnZ2NhobG5GWloYZM2aIM0cuX76MqKgo7Ny5ExEREeK658+fx9GjR/HZZ5+12O7HH3+MqqoqPPbYY3Bzc0NeXh5ef/11vPzyy4rax9AmIlXp7tAGgF27diEtLQ1RUVFwcnLC1KlTsWnTJvH5xsZGlJWV4datW5L1cnJy8OCDDyImJqbFNvv06YMtW7Zg4cKFEAQBw4YNw4YNG5CcnKyobRqhi88FtVgs0Ov1MJvNdv2k6S72XGVMDXrrqbykTh35fjev6+fn1+JmK62xWq2oqqpSfZZ0Nva0iUhV1NDTVjOGNhGpCkNbHkObiFSFoS2PoU1EqmLvHWl45xoiIhVgT1seQ5uIVKe3BrI9GNpEpCr2BnZvDXaGNhGpCkNbHkObiFSFoS2vy0Pb1jVwqX34PpKaNP89diRQGdryujy0b968CeCXa+BSx+n1+u5uAlELN2/ebPffJkNbXpeHdkBAACoqKuDh4SF7fQ+LxYLAwMAW18rtqe6n/bmf9gXg/nQmQRBw8+bNVu+jqGQbnVnvftPloe3k5IQHH3zQ7vr2Xiu3p7if9ud+2heA+9NZOvrrj6EtjwciiUhVrFarXVfZZGgTEakAe9ryVBvaWq0WGRkZHbqrsprcT/tzP+0LwP1RG4a2vC6/CQIRUWuab4LQp08fu4dHGhsbeRMEIqLuxJ62vLbv6UNE1IWar/Jnz+Ioa9aswYQJE+Du7g5PT0+7271ixQr4+/ujb9++iI6Oxrlz5yR1bty4gcTEROh0Onh6emLOnDmora1V1DaGNhGpihpCu6GhAdOmTcPcuXPtXufNN9/Epk2bkJ2djaKiIvTr1w+xsbG4ffu2WCcxMRFnz55FXl4ePvnkExw9ehQpKSnKGicQEamA2WwWAAgajUZwcnJqc9FoNAIAwWw2O6xN27ZtE/R6fZv1rFarYDAYhHXr1ollNTU1glarFd577z1BEAThu+++EwAIxcXFYp2///3vgkajES5fvmx3m7q1p71lyxYEBQXBzc0NRqMRJ06ckK3//vvvIyQkBG5ubhg1ahQ+++yzLmqpvKysLIwfPx4eHh7w9fVFQkICysrKZNfZvn07NBqNZHFzc+uiFtu2cuXKFu0KCQmRXUetnwsABAUFtdgfjUaD1NTUVuur7XM5evQonn76aQQEBECj0eDAgQOS5wU7fpK3Rul3rysJggCr1drmItx1HaO7l/r6+i5v88WLF2EymRAdHS2W6fV6GI1GFBYWAgAKCwvh6emJ8PBwsU50dDScnJxQVFRk92t1W2jv3bsX6enpyMjIwMmTJzFmzBjExsaiurq61frHjh3Ds88+izlz5uDUqVNISEhAQkICzpw508Utb+nIkSNITU3F8ePHkZeXh8bGRsTExKCurk52PZ1Oh8rKSnG5dOlSF7VY3iOPPCJp15dffmmzrpo/FwAoLi6W7EteXh4AYNq0aTbXUdPnUldXhzFjxmDLli2tPm/PT/J7Kf3udRVXV1cYDAZF6/Tv3x+BgYHQ6/XikpWV5aAW2mYymQAAfn5+knI/Pz/xOZPJBF9fX8nzLi4u8PLyEuvYxe4+eSeLiIgQUlNTxcdNTU1CQECAkJWV1Wr9Z555RoiPj5eUGY1G4Y9//KND29ke1dXVAgDhyJEjNuvY+7Orq2VkZAhjxoyxu35P+lwEQRBeeuklYejQoYLVam31ebV+LoIgCACE/fv3i4/t+UneGqXfva70888/C2az2e6lpqamRdnt27db3faSJUsEALJLaWmpZB17/x6++uorAYBw5coVSfm0adOEZ555RhAEQVizZo3w8MMPt1jXx8dH+Mtf/mLnO9RNwyMNDQ0oKSmR/JRwcnJCdHS0+FPiXoWFhZL6ABAbG2uzfncym80AAC8vL9l6tbW1GDx4MAIDAzFlyhScPXu2K5rXpnPnziEgIABDhgxBYmIiysvLbdbtSZ9LQ0MD/vrXv+IPf/iD7DxgtX4u97LnJ/m92vPd60pubm7iNVPsWfR6fYsyWycVLVq0CKWlpbLLkCFD2tXu5l8IVVVVkvKqqirxOYPB0OLXzJ07d3Djxg1FvzC6ZZ72tWvX0NTU1OpPie+//77VdUwmk+xPD7WwWq1YsGABHn/8cYwcOdJmveHDhyMnJwejR4+G2WzG+vXrMWHCBJw9e1bRBbU6m9FoxPbt2zF8+HBUVlZi1apV+NWvfoUzZ87Aw8OjRf2e8rkAwIEDB1BTU4PZs2fbrKPWz6U19vwkv1d7vnv3Cx8fH/j4+Dhk28HBwTAYDMjPz8fYsWMB/DLWXlRUJM5AiYyMRE1NDUpKShAWFgYAOHz4MKxWK4xGo92vxZNrOllqairOnDkjOw4M/PIBRkZGio8nTJiAESNG4O2330ZmZqajm2nTpEmTxH+PHj0aRqMRgwcPxr59+zBnzpxua1dn2Lp1KyZNmiR72VC1fi7UtcrLy3Hjxg2Ul5ejqakJp0+fBgAMGzYM/fv3BwCEhIQgKysL//Zv/waNRoMFCxbgtddew0MPPYTg4GAsX74cAQEBSEhIAACMGDECcXFxSE5ORnZ2NhobG5GWloYZM2YoupRtt4S2t7c3nJ2dZX9K3MtgMCiq3x3S0tLEuZdKe2V9+vTBuHHjcP78eQe1rn08PT3x8MMP22xXT/hcAODSpUv4/PPP8cEHHyhaT62fCyD9Se7v7y+WV1VVib29e7Xnu9cbrVixAjt27BAfjxs3DgDwxRdfYOLEiQCAsrIycSgUABYvXoy6ujqkpKSgpqYGTzzxBHJzcyWzj3bt2oW0tDRERUXByckJU6dOxaZNmxS1rVvGtF1dXREWFob8/HyxzGq1Ij8/X9LLuVtkZKSkPgDk5eXZrN+VBEFAWloa9u/fj8OHDyM4OFjxNpqamvDtt99KvnxqUFtbiwsXLthsl5o/l7tt27YNvr6+iI+PV7SeWj8XQPqTvFnzT3Jb7397vnu90fbt21s9mac5sIFfvvd3D7VpNBqsXr0aJpMJt2/fxueff46HH35Ysl0vLy/s3r0bN2/ehNlsRk5Ojthzt5vdhyw72Z49ewStVits375d+O6774SUlBTB09NTMJlMgiAIwu9//3th6dKlYv2vvvpKcHFxEdavXy+UlpYKGRkZQp8+fYRvv/22u3ZBNHfuXEGv1wsFBQVCZWWluNy6dUusc+/+rFq1Sjh48KBw4cIFoaSkRJgxY4bg5uYmnD17tjt2QbRo0SKhoKBAuHjxovDVV18J0dHRgre3t1BdXS0IQs/6XJo1NTUJgwYNEpYsWdLiObV/Ljdv3hROnTolnDp1SgAgbNiwQTh16pRw6dIlQRAE4Y033hA8PT2FDz/8UPjmm2+EKVOmCMHBwcLPP/8sbuOpp54SNm/eLD5u67tH6tatZ0Ru3rxZGDRokODq6ipEREQIx48fF5978sknhVmzZknq79u3T3j44YcFV1dX4ZFHHhE+/fTTLm5x62Bj+tC2bdvEOvfuz4IFC8R99/PzEyZPniycPHmy6xt/j+nTpwv+/v6Cq6urMHDgQGH69OnC+fPnxed70ufS7ODBgwIAoaysrMVzav9cvvjii1b/tprbbLVaheXLlwt+fn6CVqsVoqKiWuzn4MGDhYyMDEmZ3HeP1I2XZiUi6kF4wSgioh6EoU1E1IMwtImIehCGNhFRD8LQJiLqQRjaREQ9CEObiKgHYWgTEfUgDG0ioh6EoU1E1IMwtImIehCGNhFRD/L/ASCdCc5G3fhBAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 400x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image = ler_arq_imagens('X.txt')\n",
        "reconstruct_image(5,image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LDKiNpRBh7Cd"
      },
      "outputs": [],
      "source": [
        "# Funções de ativações para testes\n",
        "\n",
        "def sigmoid(x, der=False):\n",
        "    if der:\n",
        "        fx = sigmoid(x)\n",
        "        return fx * (1 - fx)\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def tanh(x, der=False):\n",
        "    if der:\n",
        "        return 1 - np.tanh(x) ** 2\n",
        "    return np.tanh(x)\n",
        "\n",
        "def relu(x, der=False):\n",
        "    if der:\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def leaky_relu(x, der=False):\n",
        "    alpha = 0.01\n",
        "    if der:\n",
        "        return np.where(x > 0, 1, alpha)\n",
        "    return np.where(x > 0, x, alpha * x)\n",
        "\n",
        "def soft_max(x, der=False):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x)\n",
        "\n",
        "def activation_function(x, func, der=False):\n",
        "    return func(x, der)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LQorz4O-7GP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XJnD2TDHZgUw"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self, input_size, output_size, learning_rate, act_fun, output_layer=False):\n",
        "        \"\"\"\n",
        "        Inicializa uma nova camada na rede neural.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Número de neurônios na camada anterior ou tamanho dos dados de entrada.\n",
        "            output_size (int): Número de neurônios na camada atual.\n",
        "            learning_rate (float): Taxa de aprendizado usada para ajustar os pesos e biases durante o treinamento.\n",
        "            act_fun (function): Função de ativação da camada.\n",
        "            output_layer (bool): Booleano que indica se a camada é a de saída da MLP ou não.\n",
        "\n",
        "        Attributes:\n",
        "            weights (np.array): Matriz de pesos, onde cada peso conecta um neurônio de entrada a um neurônio de saída.\n",
        "            biases (np.array): Vetor de biases, um para cada neurônio de saída.\n",
        "            weighted_input (np.array): Armazena a entrada ponderada (antes da aplicação de qualquer função de ativação).\n",
        "            output_data (np.array): Armazena a saída da camada, que neste caso é simplesmente a entrada ponderada.\n",
        "            input_data (np.array): Armazena a entrada da camada antes da ponderação.\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.act_fun = act_fun\n",
        "        self.output_layer = output_layer\n",
        "        self.weights = np.random.randn(input_size, output_size)  \n",
        "        self.biases = np.random.randn(1, output_size) \n",
        "        self.weighted_input = None\n",
        "        self.output_data = None\n",
        "        self.input_data = None\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        \"\"\"\n",
        "        Realiza o feed forward da camada.\n",
        "\n",
        "        :param input_data: Vetor de dados de entrada.\n",
        "        :return: Saída após multiplicação pelos pesos e função de ativação.\n",
        "        \"\"\"\n",
        "        self.input_data = input_data\n",
        "        self.weighted_input = np.dot(input_data, self.weights) + self.biases\n",
        "        self.output_data = activation_function(self.weighted_input, self.act_fun)\n",
        "\n",
        "        return self.output_data\n",
        "\n",
        "    def backward(self, error):\n",
        "        \"\"\"\n",
        "        Realiza o backward propagation da camada.\n",
        "\n",
        "        :param error: Erros que serão usados para calcular a correção dos pesos.\n",
        "        :return: Gradientes para serem usados na correção da camada abaixo.\n",
        "        \"\"\"\n",
        "        # Caso não seja a camada de saída, multiplica o erro pela derivada da função de ativação sobre a entrada ponderada da camada.\n",
        "        if not self.output_layer:\n",
        "            error = error * activation_function(self.weighted_input, self.act_fun, True)\n",
        "\n",
        "        if self.input_data.ndim == 1:\n",
        "            self.input_data = self.input_data.reshape(1, -1)  # Garante que input_data é bidimensional\n",
        "        if error.ndim == 1:\n",
        "            error = error.reshape(1, -1)  # Garante que error é bidimensional\n",
        "\n",
        "        # Calcula correções e gradientes\n",
        "        input_error = np.dot(error, self.weights.T)\n",
        "        weights_error = np.dot(self.input_data.T, error)\n",
        "\n",
        "        # Atualiza pesos e biases\n",
        "        self.weights += self.learning_rate * weights_error\n",
        "        self.biases += self.learning_rate * np.sum(error, axis=0, keepdims=True)\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VQ_7l4FUsnEh"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Inicializa a rede neural com camadas especificadas.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float): Taxa de aprendizado usada para ajustar os pesos e biases durante o treinamento.\n",
        "\n",
        "        Attributes:\n",
        "            learning_rate (float): Taxa de aprendizado da rede neural.\n",
        "            hidden_layer1 (Layer): Primeira camada oculta da rede neural.\n",
        "            hidden_layer2 (Layer): Segunda camada oculta da rede neural.\n",
        "            output_layer (Layer): Camada de saída da rede neural.\n",
        "            final_output (np.array): Armazena a saída final da rede após a propagação direta.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.hidden_layer1 = Layer(120, 80, self.learning_rate, sigmoid)\n",
        "        self.hidden_layer2 = Layer(80, 50, self.learning_rate, sigmoid)\n",
        "        self.output_layer = Layer(50, 26, self.learning_rate, leaky_relu, True)\n",
        "        self.final_output = None\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        \"\"\"\n",
        "        Realiza a propagação para frente através de toda a rede.\n",
        "\n",
        "        Args:\n",
        "            input_data (np.array): Dados de entrada para a rede.\n",
        "\n",
        "        Returns:\n",
        "            np.array: Saída final da rede.\n",
        "        \"\"\"\n",
        "        output = self.hidden_layer1.forward(input_data)\n",
        "        output = self.hidden_layer2.forward(output)\n",
        "        self.final_output = self.output_layer.forward(output)\n",
        "        return self.final_output\n",
        "\n",
        "    def back_propagation(self, output_error):\n",
        "        \"\"\"\n",
        "        Realiza a propagação para trás através de toda a rede.\n",
        "\n",
        "        Args:\n",
        "            output_error (np.array): Erro na saída da rede.\n",
        "        \"\"\"\n",
        "        error = self.output_layer.backward(output_error)\n",
        "        error = self.hidden_layer2.backward(error)\n",
        "        self.hidden_layer1.backward(error)\n",
        "\n",
        "    def save_weights(self, file_name):\n",
        "        \"\"\"\n",
        "        Armazena os pesos das camadas num arquivo.\n",
        "\n",
        "        Args:\n",
        "            file_name (string): Nome do arquivo que irá armazenar os valores.\n",
        "        \"\"\"\n",
        "        # Criando um dicionário para salvar os pesos de todas as camadas\n",
        "        network = {\n",
        "            # Conversão dos pesos da primeira camada oculta para uma lista\n",
        "            'hidden_layer1': {'weights': self.hidden_layer1.weights.tolist(),\n",
        "                            'biases': self.hidden_layer1.biases.tolist()},\n",
        "\n",
        "            # Conversão dos pesos da segunda camada oculta para uma lista\n",
        "            'hidden_layer2': {'weights': self.hidden_layer2.weights.tolist(),\n",
        "                            'biases': self.hidden_layer2.biases.tolist()},\n",
        "\n",
        "            # Conversão dos pesos da camada de saída para uma lista\n",
        "            'output_layer': {'weights': self.output_layer.weights.tolist(),\n",
        "                            'biases': self.output_layer.biases.tolist()}\n",
        "        }\n",
        "\n",
        "        # Abertura do arquivo para escrita\n",
        "        with open(file_name, 'w') as f:\n",
        "            # Salvando o dicionário no fomrato JSON\n",
        "            json.dump(network, f) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yQ1pTuonxJnC"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron:\n",
        "    def __init__(self, min_output_error, max_epochs_num, early_stop_param):\n",
        "        \"\"\"\n",
        "        Inicializa os parâmetros para o treinamento da rede neural.\n",
        "\n",
        "        Args:\n",
        "            min_output_error (float): Erro mínimo desejado para o treinamento.\n",
        "            max_epochs_num (int): Número máximo de épocas para o treinamento.\n",
        "            early_stop_param (int): Número de épocas consecutivas com aumento do erro permitido antes da parada antecipada.\n",
        "\n",
        "        Attributes:\n",
        "            min_output_error (float): Erro mínimo desejado para o treinamento.\n",
        "            max_epochs_num (int): Número máximo de épocas para o treinamento.\n",
        "            early_stop_param (int): Número de épocas consecutivas com aumento do erro permitido antes da parada antecipada.\n",
        "            negative_error_var_num (int): Contador de épocas com aumento do erro.\n",
        "            current_epoch_error (float): Taxa de erro da época atual.\n",
        "            last_epoch_error (float): Taxa de erro da última época.\n",
        "        \"\"\"\n",
        "        self.min_output_error = min_output_error\n",
        "        self.max_epochs_num = max_epochs_num\n",
        "        self.early_stop_param = early_stop_param\n",
        "        self.negative_error_var_num = 0\n",
        "        self.current_epoch_error = 0\n",
        "        self.last_epoch_error = 0\n",
        "\n",
        "        # Lista para armazenar os erros de treinamento em cada época\n",
        "        self.training_errors = []\n",
        "\n",
        "    def train(self, entrada, classes, neural_network):\n",
        "        \"\"\"\n",
        "        Treina a rede neural usando o conjunto de dados de treinamento.\n",
        "\n",
        "        Args:\n",
        "            entrada (np.array): Dados de entrada para treinamento.\n",
        "            classes (np.array): Labels correspondentes para o treinamento.\n",
        "            neural_network (NeuralNetwork): Instância da rede neural a ser treinada.\n",
        "        \"\"\"\n",
        "        # Divide os dados de entrada num conjunto de treinamento e outro de validação\n",
        "        x_train, y_train, x_val, y_val = dividir_dados(entrada, classes)\n",
        "        \n",
        "        # Treina a MLP\n",
        "        for epoch in range(self.max_epochs_num):\n",
        "            epoch_error = 0\n",
        "\n",
        "            # Loop que treina a MLP com os dados de treinamento\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                output = neural_network.forward_propagation(x)\n",
        "                output_error = y - output\n",
        "                neural_network.back_propagation(output_error)\n",
        "                epoch_error += np.mean(np.abs(output_error))\n",
        "\n",
        "            self.training_errors.append(epoch_error)\n",
        "\n",
        "            # Calcula a acurácia do modelo\n",
        "            acuracia = self.get_accuracy(x_val, y_val, neural_network)\n",
        "\n",
        "            # Printa erro e acurácia a cada dez épocas\n",
        "            if epoch % 10 == 0:\n",
        "                print(\n",
        "                    f\"Época {epoch}/{self.max_epochs_num}, Acurácia: {acuracia}, Erro: {epoch_error}\")\n",
        "\n",
        "            # Verifica parâmetros de early stop\n",
        "            if epoch_error < self.min_output_error:\n",
        "                print(\"Erro mínimo atingido. Parando o treinamento.\")\n",
        "                break\n",
        "            \n",
        "            # Verifica se o erro aumentou\n",
        "            if epoch > 0 and self.training_errors[epoch] > self.training_errors[epoch - 1]:\n",
        "                self.negative_error_var_num += 1\n",
        "            else:\n",
        "                self.negative_error_var_num = 0\n",
        "\n",
        "            if self.negative_error_var_num >= self.early_stop_param:\n",
        "                print(\"Parando antecipadamente devido ao aumento contínuo do erro.\")\n",
        "                break\n",
        "\n",
        "        neural_network.save_weights(\"pesos_mlp.txt\")\n",
        "        return neural_network\n",
        "    \n",
        "    def get_accuracy(self, entrada, saida_esperada, neural_network):\n",
        "        \"\"\"\n",
        "        Obtém a acurácia da rede neural passada como parâmetro.\n",
        "\n",
        "        Args:\n",
        "            entrada (np.array): Dados de entrada para teste.\n",
        "            saida_esperada (np.array): Saída esperada da rede neural.\n",
        "            neural_network (NeuralNetwork): Instância da rede neural treinada.\n",
        "\n",
        "        Returns:\n",
        "            acuracia (float): Porcentagem de acertos da rede.\n",
        "        \"\"\"\n",
        "\n",
        "        # Inicializa variáveis para calcular acurácia\n",
        "        num_testes = 0\n",
        "        num_acertos = 0\n",
        "\n",
        "        # Realiza teste para cada um dos dados de entrada\n",
        "        for x, y in zip(entrada, saida_esperada):\n",
        "            num_testes += 1\n",
        "            \n",
        "            # Realiza a predição\n",
        "            predicao = neural_network.forward_propagation(x)\n",
        "\n",
        "            # Obtém a letra predita pelo modelo\n",
        "            letra_predita = vetor_para_letra(predicao)\n",
        "\n",
        "            # Obtém a letra esperada\n",
        "            letra_real = vetor_para_letra(y)\n",
        "\n",
        "            if letra_predita == letra_real:\n",
        "                num_acertos += 1\n",
        "        \n",
        "        acuracia = num_acertos / num_testes\n",
        "\n",
        "        return acuracia\n",
        "\n",
        "    def predict(self, entrada, neural_network):\n",
        "        \"\"\"\n",
        "        Realiza predições usando a rede neural treinada.\n",
        "\n",
        "        Args:\n",
        "            entrada (np.array): Dados de entrada para teste.\n",
        "            neural_network (NeuralNetwork): Instância da rede neural treinada.\n",
        "\n",
        "        Returns:\n",
        "            np.array: Predições da rede neural.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for x in entrada:\n",
        "            output = neural_network.forward_propagation(x)\n",
        "            predictions.append(output)\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Lendo os arquivos\n",
        "    imagens = ler_arq_imagens('X.txt')\n",
        "    classes = ler_arq_classes('Y_letra.txt')\n",
        "\n",
        "    # Dividindo os dados em conjuntos de treinamento e teste\n",
        "    x_train, y_train, x_test, y_test = dividir_dados(imagens, classes)\n",
        "\n",
        "    # Convertendo para float\n",
        "    y_train = y_train.astype(float)\n",
        "    y_test = y_test.astype(float)\n",
        "\n",
        "    # Inicializa a rede neural\n",
        "    neural_network = NeuralNetwork(learning_rate=0.01)\n",
        "\n",
        "    # Parâmetros para o treinamento\n",
        "    min_output_error = 0.001\n",
        "    max_epochs_num = 500\n",
        "    early_stop_param = 100\n",
        "\n",
        "    # Inicializa o Multilayer Perceptron com os parâmetros de treinamento\n",
        "    mlp = MultilayerPerceptron(min_output_error, max_epochs_num, early_stop_param)\n",
        "\n",
        "    # Treina a rede neural\n",
        "    mlp.train(x_train, y_train, neural_network)\n",
        "\n",
        "    # Testa a rede neural\n",
        "    predictions = mlp.predict(x_test, neural_network)\n",
        "\n",
        "    # Exibe algumas predições para verificação\n",
        "    num_testes = 0\n",
        "    acertos = 0\n",
        "    for i in range(20):\n",
        "        num_testes += 1\n",
        "\n",
        "        predicao = vetor_para_letra(predictions[i])\n",
        "        correto = vetor_para_letra(y_test[i])\n",
        "\n",
        "        if predicao == correto:\n",
        "            acertos += 1\n",
        "        print(f\"Predição: {predicao}, Real: {correto}\")\n",
        "\n",
        "    print(f\"Acurácia: {acertos/num_testes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1326\n",
            "1326\n",
            "1060\n",
            "1060\n",
            "Época 0/500, Acurácia: 0.04245283018867924, Erro: 355.9382613212614\n",
            "Época 10/500, Acurácia: 0.25, Erro: 124.66906310488099\n",
            "Época 20/500, Acurácia: 0.4669811320754717, Erro: 120.60210718866276\n",
            "Época 30/500, Acurácia: 0.589622641509434, Erro: 122.25907161245134\n",
            "Época 40/500, Acurácia: 0.6556603773584906, Erro: 125.35855433723229\n",
            "Época 50/500, Acurácia: 0.7358490566037735, Erro: 127.61766856420614\n",
            "Época 60/500, Acurácia: 0.7358490566037735, Erro: 127.83908563903083\n",
            "Época 70/500, Acurácia: 0.7688679245283019, Erro: 126.23770273751938\n",
            "Época 80/500, Acurácia: 0.7924528301886793, Erro: 123.65869567302401\n",
            "Época 90/500, Acurácia: 0.7924528301886793, Erro: 119.41443368565106\n",
            "Época 100/500, Acurácia: 0.8066037735849056, Erro: 114.19506878671353\n",
            "Época 110/500, Acurácia: 0.8018867924528302, Erro: 107.97161664543185\n",
            "Época 120/500, Acurácia: 0.8018867924528302, Erro: 107.42385797779608\n",
            "Época 130/500, Acurácia: 0.8160377358490566, Erro: 96.9514182442579\n",
            "Época 140/500, Acurácia: 0.8160377358490566, Erro: 91.98987349160548\n",
            "Época 150/500, Acurácia: 0.8066037735849056, Erro: 89.49567014443946\n",
            "Época 160/500, Acurácia: 0.7830188679245284, Erro: 82.71351558885196\n",
            "Época 170/500, Acurácia: 0.8018867924528302, Erro: 79.86613100602148\n",
            "Época 180/500, Acurácia: 0.7971698113207547, Erro: 76.05886515763858\n",
            "Época 190/500, Acurácia: 0.8018867924528302, Erro: 73.99511911084413\n",
            "Época 200/500, Acurácia: 0.7971698113207547, Erro: 73.06712253818918\n",
            "Época 210/500, Acurácia: 0.8066037735849056, Erro: 69.81656044324691\n",
            "Época 220/500, Acurácia: 0.7971698113207547, Erro: 66.99918093205515\n",
            "Época 230/500, Acurácia: 0.7971698113207547, Erro: 64.31297925541193\n",
            "Época 240/500, Acurácia: 0.8160377358490566, Erro: 62.54944312272553\n",
            "Época 250/500, Acurácia: 0.8018867924528302, Erro: 61.146944343335235\n",
            "Época 260/500, Acurácia: 0.8018867924528302, Erro: 61.177816884470836\n",
            "Época 270/500, Acurácia: 0.8066037735849056, Erro: 58.128215905837\n",
            "Época 280/500, Acurácia: 0.8066037735849056, Erro: 56.94155987569739\n",
            "Época 290/500, Acurácia: 0.8018867924528302, Erro: 57.33094614810102\n",
            "Época 300/500, Acurácia: 0.8066037735849056, Erro: 54.552687071911826\n",
            "Época 310/500, Acurácia: 0.8113207547169812, Erro: 54.17202326000132\n",
            "Época 320/500, Acurácia: 0.8018867924528302, Erro: 51.91324073984819\n",
            "Época 330/500, Acurácia: 0.8160377358490566, Erro: 51.26323956017863\n",
            "Época 340/500, Acurácia: 0.8113207547169812, Erro: 50.57918664673796\n",
            "Época 350/500, Acurácia: 0.8207547169811321, Erro: 49.593101995753536\n",
            "Época 360/500, Acurácia: 0.8066037735849056, Erro: 48.44746017016354\n",
            "Época 370/500, Acurácia: 0.8066037735849056, Erro: 47.35938421613733\n",
            "Época 380/500, Acurácia: 0.8207547169811321, Erro: 48.533673235054856\n",
            "Época 390/500, Acurácia: 0.8254716981132075, Erro: 46.5614669716645\n",
            "Época 400/500, Acurácia: 0.7971698113207547, Erro: 99.09424068458601\n",
            "Época 410/500, Acurácia: 0.8113207547169812, Erro: 62.17879205411732\n",
            "Época 420/500, Acurácia: 0.8349056603773585, Erro: 46.5941891585527\n",
            "Época 430/500, Acurácia: 0.8207547169811321, Erro: 43.0540465430833\n",
            "Época 440/500, Acurácia: 0.8301886792452831, Erro: 40.71737836237561\n",
            "Época 450/500, Acurácia: 0.8301886792452831, Erro: 41.008104749965064\n",
            "Época 460/500, Acurácia: 0.8160377358490566, Erro: 39.39232120214166\n",
            "Época 470/500, Acurácia: 0.8160377358490566, Erro: 38.574523910391235\n",
            "Época 480/500, Acurácia: 0.8301886792452831, Erro: 37.54164794897528\n",
            "Época 490/500, Acurácia: 0.8254716981132075, Erro: 36.57762324888824\n",
            "Predição: Y, Real: M\n",
            "Predição: L, Real: L\n",
            "Predição: J, Real: J\n",
            "Predição: W, Real: W\n",
            "Predição: M, Real: H\n",
            "Predição: O, Real: O\n",
            "Predição: R, Real: R\n",
            "Predição: H, Real: H\n",
            "Predição: Y, Real: Y\n",
            "Predição: C, Real: C\n",
            "Predição: R, Real: R\n",
            "Predição: I, Real: I\n",
            "Predição: T, Real: J\n",
            "Predição: I, Real: I\n",
            "Predição: L, Real: L\n",
            "Predição: V, Real: V\n",
            "Predição: U, Real: U\n",
            "Predição: B, Real: B\n",
            "Predição: I, Real: I\n",
            "Predição: I, Real: T\n",
            "Acurácia: 0.8\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Função para treinar a camada da arede neural\n",
        "def train(layer, X_train, y_train, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in zip(X_train, y_train):\n",
        "            layer.train(x, y)\n",
        "\n",
        "#Função para valiar a camada da rede nneural nos dados de teste\n",
        "def evaluate(layer, X_test, y_test):\n",
        "    correct_predictions = 0\n",
        "    for x, y_true in zip(X_test, y_test):\n",
        "        y_pred = layer.forward_layers(x)\n",
        "        if np.argmax(y_pred) == np.argmax(y_true):\n",
        "            correct_predictions += 1\n",
        "    accuracy = correct_predictions / len(X_test)\n",
        "    return accuracy\n",
        "\n",
        "#Função do Cross-validation\n",
        "def cross_validation(layer_class, X, y, k=5, epochs=100, learning_rate=0.01):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Cria uma nova instância da camada para cada fold\n",
        "        input_size = X.shape[1]\n",
        "        output_size = y.shape[1]\n",
        "        layer = layer_class(input_size, output_size, learning_rate)\n",
        "\n",
        "        # Treina a camada\n",
        "        train(layer, X_train, y_train, epochs)\n",
        "\n",
        "        # Avalia a camada\n",
        "        accuracy = evaluate(layer, X_test, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    return mean_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6wKX05Ojl8W"
      },
      "source": [
        "Exemplo de uso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhSXY_Wzsrnf"
      },
      "outputs": [],
      "source": [
        "imagens = ler_arq_imagens('X.txt')\n",
        "classes = ler_arq_classes('Y_letra.txt')\n",
        "print(imagens.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executando o treinamento e teste da rede neural\n",
        "mlp = MultilayerPerceptron()\n",
        "mlp.main(imagens, classes)#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o erro de treinamento\n",
        "plt.plot(mlp.training_errors)\n",
        "plt.title('Erro de Treinamento por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criação de uma tabela com os erros de treinamento\n",
        "df_erros_treinamento = pd.DataFrame({\n",
        "    'Época': range(len(mlp.training_errors)),\n",
        "    'Erro': mlp.training_errors\n",
        "})\n",
        "\n",
        "# Exibindo a tabela\n",
        "print(df_erros_treinamento)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Falta:\n",
        "\n",
        "- fazer o erro parar de diminuir pouco\n",
        "- tirar sklearn do cross-validation\n",
        "- verificar se o gráfico tá gerando certo\n",
        "- gerar matriz de confusão para testes da rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roteiro para vídeo\n",
        "\n",
        "V1:\n",
        "- Parte de treinamento do código (com e sem validação cruzada e parada antecipada) PARA: conjunto de dados CARACTERES COMPLETO (os outros de teste não entram)\n",
        "- Estudo dos parâmetros (busca por valores adequados – grid) (?)\n",
        "- Teste da MLP para o conjunto de dados CARACTERES COMPLETO\n",
        "\n",
        "V2:\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
