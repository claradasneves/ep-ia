{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGUvj5itk-3m"
      },
      "source": [
        "# Trabalho de IA: MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuOcZ8Nto_bY"
      },
      "source": [
        "- Fazer leitura dos dados testes\n",
        "- Fazer o loop das épocas\n",
        "- Conferir o backpropagation\n",
        "- Testar com conj binários\n",
        "\n",
        "Depois:\n",
        "Otimização e análise\n",
        "- Parada antecipada\n",
        "- Rever o doc de especificação do trabalho para montar os gráficos\n",
        "- Começar a guardar os pesos (e perguntar pra prof o porquê)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN8ONKTblF9z"
      },
      "source": [
        "##Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRTRIhbRmLbE"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import math\n",
        "from graphviz import Digraph\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0sIq_i-l53g"
      },
      "outputs": [],
      "source": [
        "alfabeto = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "\n",
        "# Função que transforma letra em vetor\n",
        "def letra_para_vetor(letra):\n",
        "    vetor = [0] * 26\n",
        "    pos_letra = alfabeto.index(letra)\n",
        "    vetor[pos_letra] = 1\n",
        "\n",
        "    return vetor\n",
        "\n",
        "# Função que transforma vetor em letra\n",
        "def vetor_para_letra(vetor):\n",
        "    # Encontra a posição do maior valor no vetor\n",
        "    maior_pos = np.argmax(vetor)\n",
        "\n",
        "    # Encontra a letra correspondente no alfabeto\n",
        "    letra = alfabeto[maior_pos]\n",
        "\n",
        "    return letra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ler_arq_imagens(nome_arq):\n",
        "    \"\"\"\n",
        "    Lê o arquivo de imagens e retorna um array numpy.\n",
        "\n",
        "    Args:\n",
        "        nome_arq (str): Caminho para o arquivo de imagens.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array numpy contendo as imagens.\n",
        "    \"\"\"\n",
        "    with open(nome_arq, 'r') as file:\n",
        "        data = file.read().strip().split('\\n')\n",
        "    data = [list(map(int, filter(lambda x: x.strip(), line.split(',')))) for line in data if line.strip()]\n",
        "    return np.array(data)\n",
        "\n",
        "def ler_arq_classes(nome_arq):\n",
        "    \"\"\"\n",
        "    Lê o arquivo de classes e retorna um array numpy.\n",
        "\n",
        "    Args:\n",
        "        nome_arq (str): Caminho para o arquivo de classes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array numpy contendo as classes.\n",
        "    \"\"\"\n",
        "    with open(nome_arq, 'r') as file:\n",
        "        data = file.read().strip().split('\\n')\n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_labels(labels):\n",
        "    \"\"\"\n",
        "    Codifica as classes em valores numéricos únicos.\n",
        "\n",
        "    Args:\n",
        "        labels (np.ndarray): Array de classes textuais.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array de classes codificadas numericamente.\n",
        "        dict: Dicionário de mapeamento de classe para valor numérico.\n",
        "    \"\"\"\n",
        "    unique_labels = np.unique(labels)\n",
        "    label_to_num = {label: num for num, label in enumerate(unique_labels)}\n",
        "    encoded_labels = np.array([label_to_num[label] for label in labels])\n",
        "    return encoded_labels, label_to_num\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-hoEUDxPfc4"
      },
      "source": [
        "Funcao pra reconstruir imagens a partir do array de array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nD_uUiPPEYlC",
        "outputId": "a9db9514-13b0-4b09-d43e-b36ca64d539c"
      },
      "outputs": [],
      "source": [
        "def reconstruct_image(row_index, image_array):\n",
        "    \"\"\"\n",
        "    Reconstrói e plota uma imagem a partir do array numpy.\n",
        "\n",
        "    Args:\n",
        "        row_index (int): Índice da linha da imagem a ser reconstruída.\n",
        "        image_array (np.ndarray): Array numpy contendo as imagens.\n",
        "    \"\"\"\n",
        "    image_array = image_array[row_index]\n",
        "    image_reshaped = np.reshape(image_array, (10, 12))\n",
        "\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    plt.imshow(image_reshaped, cmap='gray')\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = ler_arq_imagens('X.txt')\n",
        "reconstruct_image(5,image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDKiNpRBh7Cd"
      },
      "outputs": [],
      "source": [
        "def activation(x):\n",
        "    return np.tanh(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUM7lGzksbHH"
      },
      "outputs": [],
      "source": [
        "def derivative_activation(x):\n",
        "    return 1 - np.tanh(x) ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LQorz4O-7GP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJnD2TDHZgUw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Layer:\n",
        "    def __init__(self, input_size, output_size, learning_rate):\n",
        "        \"\"\"\n",
        "        Inicializa uma nova camada na rede neural.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Número de neurônios na camada anterior ou tamanho dos dados de entrada.\n",
        "            output_size (int): Número de neurônios na camada atual.\n",
        "            learning_rate (float): Taxa de aprendizado usada para ajustar os pesos e biases durante o treinamento.\n",
        "\n",
        "        Attributes:\n",
        "            weights (np.array): Matriz de pesos, onde cada peso conecta um neurônio de entrada a um neurônio de saída.\n",
        "            biases (np.array): Vetor de biases, um para cada neurônio de saída.\n",
        "            weighted_input (np.array): Armazena a entrada ponderada (antes da aplicação de qualquer função de ativação).\n",
        "            output_data (np.array): Armazena a saída da camada, que neste caso é simplesmente a entrada ponderada.\n",
        "            input_data (np.array): Armazena a entrada da camada antes da ponderação.\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.weights = np.random.randn(input_size, output_size) # * 0.01\n",
        "        self.biases = np.random.randn(1, output_size) # * 0.01  # Corrigido para ter a forma (1, output_size)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weighted_input = None\n",
        "        self.output_data = None\n",
        "        self.input_data = None\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input_data = input_data\n",
        "        self.weighted_input = np.dot(input_data, self.weights) + self.biases\n",
        "        self.output_data = activation(self.weighted_input)\n",
        "        \n",
        "        return self.output_data\n",
        "\n",
        "    def backward(self, output_error):\n",
        "        error = output_error * derivative_activation(self.weighted_input)\n",
        "        if self.input_data.ndim == 1:\n",
        "            self.input_data = self.input_data.reshape(1, -1)  # Garantir que input_data é bidimensional\n",
        "        if error.ndim == 1:\n",
        "            error = error.reshape(1, -1)  # Garantir que error é bidimensional\n",
        "\n",
        "        input_error = np.dot(error, self.weights.T)\n",
        "        weights_error = np.dot(self.input_data.T, error)\n",
        "\n",
        "        # Atualiza pesos e biases\n",
        "        self.weights += self.learning_rate * weights_error\n",
        "        self.biases += self.learning_rate * np.sum(error, axis=0, keepdims=True)\n",
        "        return input_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ_7l4FUsnEh"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, learning_rate=0.7):\n",
        "        \"\"\"\n",
        "        Inicializa a rede neural com camadas especificadas.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float): Taxa de aprendizado usada para ajustar os pesos e biases durante o treinamento.\n",
        "\n",
        "        Attributes:\n",
        "            learning_rate (float): Taxa de aprendizado da rede neural.\n",
        "            input_layer (Layer): Camada de entrada da rede neural.\n",
        "            hidden_layer1 (Layer): Primeira camada oculta da rede neural.\n",
        "            hidden_layer2 (Layer): Segunda camada oculta da rede neural.\n",
        "            output_layer (Layer): Camada de saída da rede neural.\n",
        "            final_output (np.array): Armazena a saída final da rede após a propagação direta.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.input_layer = Layer(120, 120, self.learning_rate)\n",
        "        self.hidden_layer1 = Layer(120, 26, self.learning_rate)\n",
        "        #self.hidden_layer2 = Layer(60, 30, self.learning_rate)\n",
        "        self.output_layer = Layer(26, 26, self.learning_rate)\n",
        "        self.final_output = None\n",
        "        \n",
        "    def forward_propagation(self,input_data):\n",
        "        \"\"\"\n",
        "        Realiza a propagação para frente através de toda a rede.\n",
        "        \n",
        "        Args:\n",
        "            input_data (np.array): Dados de entrada para a rede.\n",
        "        \n",
        "        Returns:\n",
        "            np.array: Saída final da rede.\n",
        "        \"\"\"\n",
        "        output = self.input_layer.forward(input_data)\n",
        "        output = self.hidden_layer1.forward(output)\n",
        "        #output = self.hidden_layer2.forward(output)\n",
        "        self.final_output = self.output_layer.forward(output)\n",
        "        return self.final_output\n",
        "\n",
        "    def back_propagation(self, output_error):\n",
        "        \"\"\"\n",
        "        Realiza a propagação para trás através de toda a rede.\n",
        "        \n",
        "        Args:\n",
        "            output_error (np.array): Erro na saída da rede.\n",
        "        \"\"\"\n",
        "        error = self.output_layer.backward(output_error)\n",
        "        #error = self.hidden_layer2.backward(error)\n",
        "        error = self.hidden_layer1.backward(error)\n",
        "        self.input_layer.backward(error)\n",
        "\n",
        "    #Função para salvar os pesos da rede neural em um arquivo \n",
        "    def save_weights(self, file_name):\n",
        "        #Criando um dicionário para salvar os pesos de todas as camadas\n",
        "        weights = {\n",
        "            #Conversão dos pesos da camada de entrada para uma lista\n",
        "            'input_layer': self.input_layer.weights.tolist(), \n",
        "            #Conversão dos pesos da primeira camada oculta para uma lista\n",
        "            'hidden_layer1': self.hidden_layer1.weights.tolist(),\n",
        "            #Conversão dos pesos da segunda camada oculta para uma lista\n",
        "            #'hidden_layer2': self.hidden_layer2.weights.tolist(),\n",
        "            #Conversão dos pesos da camada de saída para uma lista\n",
        "            'output_layer': self.output_layer.weights.tolist(),\n",
        "        }\n",
        "        #Abertura do arquivo para escrita\n",
        "        with open(file_name, 'w') as f:\n",
        "            #Salvando o dicionário no fomrato JSON\n",
        "            json.dump(weights, f)\n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ1pTuonxJnC"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron:\n",
        "    def __init__(self, min_output_error=0.001, max_epochs_num=10000, early_stop_param=10):\n",
        "        \"\"\"\n",
        "        Inicializa os parâmetros para o treinamento da rede neural.\n",
        "\n",
        "        Args:\n",
        "            min_output_error (float): Erro mínimo desejado para o treinamento.\n",
        "            max_epochs_num (int): Número máximo de épocas para o treinamento.\n",
        "            early_stop_param (int): Número de épocas consecutivas com aumento do erro permitido antes da parada antecipada.\n",
        "\n",
        "        Attributes:\n",
        "            min_output_error (float): Erro mínimo desejado para o treinamento.\n",
        "            max_epochs_num (int): Número máximo de épocas para o treinamento.\n",
        "            early_stop_param (int): Número de épocas consecutivas com aumento do erro permitido antes da parada antecipada.\n",
        "            negative_error_var_num (int): Contador de épocas com aumento do erro.\n",
        "            current_epoch_error (float): Taxa de erro da época atual.\n",
        "            last_epoch_error (float): Taxa de erro da última época.\n",
        "        \"\"\"\n",
        "        self.min_output_error = min_output_error\n",
        "        self.max_epochs_num = max_epochs_num\n",
        "        self.early_stop_param = early_stop_param\n",
        "        self.negative_error_var_num = 0\n",
        "        self.current_epoch_error = 0\n",
        "        self.last_epoch_error = 0\n",
        "        #Lista para armazenar os erros de treinamento em cada época\n",
        "        self.training_errors = [] \n",
        "\n",
        "\n",
        "    def train(self, X_train, y_train, neural_network):\n",
        "            \"\"\"\n",
        "            Treina a rede neural usando o conjunto de dados de treinamento.\n",
        "            \n",
        "            Args:\n",
        "                X_train (np.array): Dados de entrada para treinamento.\n",
        "                y_train (np.array): Labels correspondentes para o treinamento.\n",
        "                neural_network (NeuralNetwork): Instância da rede neural a ser treinada.\n",
        "            \"\"\"\n",
        "            for epoch in range(self.max_epochs_num):\n",
        "                epoch_error = 0\n",
        "                for x, y in zip(X_train, y_train):\n",
        "                    output = neural_network.forward_propagation(x)\n",
        "                    output_error = y - output\n",
        "                    neural_network.back_propagation(output_error)\n",
        "                    epoch_error += np.mean(np.abs(output_error))\n",
        "                \n",
        "                self.training_errors.append(epoch_error)\n",
        "                print(f\"Epoch {epoch+1}/{self.max_epochs_num}, Error: {epoch_error}\")\n",
        "\n",
        "                # Early stopping criteria\n",
        "                if epoch_error < self.min_output_error:\n",
        "                    print(\"Erro mínimo atingido. Parando o treinamento.\")\n",
        "                    break\n",
        "                \n",
        "                if epoch > 0 and self.training_errors[epoch] > self.training_errors[epoch - 1]:\n",
        "                    self.negative_error_var_num += 1\n",
        "                else:\n",
        "                    self.negative_error_var_num = 0\n",
        "\n",
        "                if self.negative_error_var_num >= self.early_stop_param:\n",
        "                    print(\"Parando antecipadamente devido ao aumento contínuo do erro.\")\n",
        "                    break\n",
        "\n",
        "    def predict(self, X_test, neural_network):\n",
        "        \"\"\"\n",
        "        Realiza predições usando a rede neural treinada.\n",
        "        \n",
        "        Args:\n",
        "            X_test (np.array): Dados de entrada para teste.\n",
        "            neural_network (NeuralNetwork): Instância da rede neural treinada.\n",
        "        \n",
        "        Returns:\n",
        "            np.array: Predições da rede neural.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            output = neural_network.forward(x)\n",
        "            predictions.append(output)\n",
        "        return np.array(predictions)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dividir_dados(X, y, test_size=0.2):\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    split_idx = int(len(indices) * (1 - test_size))\n",
        "    train_indices = indices[:split_idx]\n",
        "    test_indices = indices[split_idx:]\n",
        "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Lendo os arquivos\n",
        "    imagens = ler_arq_imagens('X.txt')\n",
        "    classes = ler_arq_classes('Y_letra.txt')\n",
        "    \n",
        "    # Dividindo os dados em conjuntos de treinamento e teste\n",
        "    X_train, X_test, y_train, y_test = dividir_dados(imagens, classes, test_size=0.2)\n",
        "    \n",
        "    # Codificando as classes manualmente\n",
        "    y_train, label_to_num = encode_labels(y_train)\n",
        "    y_test, _ = encode_labels(y_test)\n",
        "\n",
        "    # Convertendo para float\n",
        "    y_train = y_train.astype(float)\n",
        "    y_test = y_test.astype(float)\n",
        "    \n",
        "    # Inicializa a rede neural\n",
        "    neural_network = NeuralNetwork(learning_rate=0.01)\n",
        "\n",
        "    # Parâmetros para o treinamento\n",
        "    min_output_error = 0.001\n",
        "    max_epochs_num = 10000\n",
        "    early_stop_param = 100\n",
        "\n",
        "    # Inicializa o Multilayer Perceptron com os parâmetros de treinamento\n",
        "    mlp = MultilayerPerceptron(min_output_error, max_epochs_num, early_stop_param)\n",
        "\n",
        "    # Treina a rede neural\n",
        "    mlp.train(X_train, y_train, neural_network)\n",
        "\n",
        "    # Testa a rede neural\n",
        "    predictions = mlp.predict(X_test, neural_network)\n",
        "\n",
        "    # Exibe algumas predições para verificação\n",
        "    for i in range(10):\n",
        "        print(f\"Predição: {predictions[i]}, Real: {y_test[i]}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Função para treinar a camada da arede neural\n",
        "def train(layer, X_train, y_train, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in zip(X_train, y_train):\n",
        "            layer.train(x, y)\n",
        "\n",
        "#Função para valiar a camada da rede nneural nos dados de teste\n",
        "def evaluate(layer, X_test, y_test):\n",
        "    correct_predictions = 0\n",
        "    for x, y_true in zip(X_test, y_test):\n",
        "        y_pred = layer.forward_layers(x)\n",
        "        if np.argmax(y_pred) == np.argmax(y_true):\n",
        "            correct_predictions += 1\n",
        "    accuracy = correct_predictions / len(X_test)\n",
        "    return accuracy\n",
        "\n",
        "#Função do Cross-validation\n",
        "def cross_validation(layer_class, X, y, k=5, epochs=100, learning_rate=0.01):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Cria uma nova instância da camada para cada fold\n",
        "        input_size = X.shape[1]\n",
        "        output_size = y.shape[1]\n",
        "        layer = layer_class(input_size, output_size, learning_rate)\n",
        "\n",
        "        # Treina a camada\n",
        "        train(layer, X_train, y_train, epochs)\n",
        "\n",
        "        # Avalia a camada\n",
        "        accuracy = evaluate(layer, X_test, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    return mean_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6wKX05Ojl8W"
      },
      "source": [
        "Exemplo de uso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhSXY_Wzsrnf"
      },
      "outputs": [],
      "source": [
        "imagens = ler_arq_imagens('X.txt')\n",
        "classes = ler_arq_classes('Y_letra.txt')\n",
        "print(imagens.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executando o treinamento e teste da rede neural\n",
        "mlp = MultilayerPerceptron()\n",
        "mlp.main(imagens, classes)#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o erro de treinamento\n",
        "plt.plot(mlp.training_errors)\n",
        "plt.title('Erro de Treinamento por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Erro')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criação de uma tabela com os erros de treinamento\n",
        "df_erros_treinamento = pd.DataFrame({\n",
        "    'Época': range(len(mlp.training_errors)),\n",
        "    'Erro': mlp.training_errors\n",
        "})\n",
        "\n",
        "# Exibindo a tabela\n",
        "print(df_erros_treinamento)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Falta:\n",
        "\n",
        "- fazer o erro parar de diminuir pouco\n",
        "- tirar sklearn do cross-validation\n",
        "- verificar se o gráfico tá gerando certo\n",
        "- gerar matriz de confusão para testes da rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roteiro para vídeo\n",
        "\n",
        "V1:\n",
        "- Parte de treinamento do código (com e sem validação cruzada e parada antecipada) PARA: conjunto de dados CARACTERES COMPLETO (os outros de teste não entram)\n",
        "- Estudo dos parâmetros (busca por valores adequados – grid) (?)\n",
        "- Teste da MLP para o conjunto de dados CARACTERES COMPLETO\n",
        "\n",
        "V2:\n",
        "- \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
